{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vivino scraping\n",
    "We use a mix of ```selenium``` to load the page and address the lazy loading and ```beautifulsoup``` to parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# make def for the arguments search and vintage to scrape vivino\n",
    "def scrape_vivino(search, vintage):\n",
    "    \n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    base = \"https://www.vivino.com/search/wines?q=\"\n",
    "    html = base + search + \"+\" + vintage\n",
    "    driver.get(html)\n",
    "    driver.implicitly_wait(0.5) # gives an implicit wait for 20 seconds\n",
    "    #try:\n",
    "    #    button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"didomi-notice-agree-button\"]')))\n",
    "    #    button.click()\n",
    "    #except NoSuchElementException:\n",
    "    #    print(\"\\tError finding xyz...\")\n",
    "\n",
    "    button = driver.find_element(By.XPATH,'/html/body/div[2]/section[1]/div/div/div/div[1]/div/div[1]/div/div[2]/div[1]/span[1]')\n",
    "                                            \n",
    "    button.click()\n",
    "    driver.implicitly_wait(0.5) # gives an implicit wait for 20 seconds\n",
    "\n",
    "    last_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "\n",
    "    #for i in range(1, total_height, 5):\n",
    "    #    driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    # Get the scroll height\n",
    "\n",
    "\n",
    "    # Scroll down step by step\n",
    "    for i in range(1, last_height, 4):\n",
    "        driver.execute_script(f\"window.scrollTo(0, {i});\")\n",
    "        time.sleep(0.08)  # Adjust this value as per your internet speed\n",
    "        last_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #save soup as html file\n",
    "    #with open('vivino.html', 'w') as file:\n",
    "    #    file.write(str(soup))\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Find all span tags with the class 'vintage'\n",
    "    vintage_spans = soup.find_all('span', class_='vintage')\n",
    "\n",
    "    # Iterate over the span tags\n",
    "    for span in vintage_spans:\n",
    "        # Find the a tag with the class 'wine' within this span\n",
    "        a_tag = span.find('a', class_='wine')\n",
    "        \n",
    "        # Extract the text from the a tag\n",
    "        name = a_tag.text.strip()\n",
    "        \n",
    "        # Find the next sibling of the a tag and extract its text\n",
    "        year = a_tag.next_sibling.strip()\n",
    "\n",
    "\n",
    "    # Find all elements with the class 'bottleShot'\n",
    "    bottle_shots = soup.find_all(class_='bottleShot')\n",
    "\n",
    "    # Iterate over the elements with the class 'bottleShot'\n",
    "    for bottle_shot in bottle_shots:\n",
    "        # Find all source tags within this element\n",
    "        source_tags = bottle_shot.find_all('source')\n",
    "        \n",
    "        # Iterate over the source tags\n",
    "        for tag in source_tags:\n",
    "            # Split the srcset attribute on comma and space to get the individual URLs\n",
    "            urls = tag['srcset'].split(', ')\n",
    "            \n",
    "            \n",
    "            # Split the URL on space to separate the URL and the resolution\n",
    "            url, resolution = urls[1].split(' ')\n",
    "            \n",
    "            # Check if the resolution is '2x'\n",
    "            if resolution == '2x':\n",
    "                # Remove the \"//\" at the beginning of the URL\n",
    "                final_url = 'https:' + url\n",
    "                \n",
    "                # Download the image\n",
    "                response = requests.get(final_url, stream=True)\n",
    "                if response.status_code == 200:\n",
    "                    with open(f'{name} {year}.png', 'wb') as out_file:\n",
    "                        out_file.write(response.content)\n",
    "\n",
    "    # Find all span tags with the class 'headline'\n",
    "    headline_spans = soup.find_all('span', class_='headline')\n",
    "\n",
    "\n",
    "    # Iterate over the span tags\n",
    "    for span in headline_spans:\n",
    "        # Find the a tag with the class 'winery' within this span\n",
    "        a_tag = span.find('a', class_='winery')\n",
    "        \n",
    "        # Extract the text from the a tag and add it to the list\n",
    "        winery = a_tag.text.replace('\\n', '')\n",
    "\n",
    "    # Find the a tag with data-cy=\"breadcrumb-country\"\n",
    "    tag = soup.find('a', {'data-cy': 'breadcrumb-country'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    country = tag.text\n",
    "\n",
    "    # Find the a tag with data-cy=\"breadcrumb-region\"\n",
    "    tag = soup.find('a', {'data-cy': 'breadcrumb-region'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    region = tag.text\n",
    "\n",
    "    # Find the a tag with data-cy=\"breadcrumb-winetype\"\n",
    "    tag = soup.find('a', {'data-cy': 'breadcrumb-winetype'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    category = tag.text\n",
    "\n",
    "\n",
    "    # Find the a tag with data-cy=\"breadcrumb-grape\"\n",
    "    tag = soup.find('a', {'data-cy': 'breadcrumb-grape'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    grape_type = tag.text\n",
    "\n",
    "\n",
    "    # Find the h3 tag with class=\"wineTasteStyle-desktop__wineName--ML0zS\"\n",
    "    tag = soup.find('h3', {'class': 'wineTasteStyle-desktop__wineName--ML0zS'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    wine_style = tag.text\n",
    "\n",
    "\n",
    "    # Find all the rows in the table\n",
    "    rows = soup.select('.tasteStructure__tasteCharacteristic--jLtsE')\n",
    "    percentages=[]\n",
    "    # For each row\n",
    "    for row in rows:\n",
    "        # Find the cells\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        # The first cell contains the first property\n",
    "        property1 = cells[0].text.strip()\n",
    "\n",
    "        # The second cell contains the style attribute with the percentage\n",
    "        style = cells[1].select_one('.indicatorBar__progress--3aXLX')['style']\n",
    "        percentage = re.search(r'left:\\s(\\d+).\\d+%;', style).group(1)\n",
    "\n",
    "        # The third cell contains the second property\n",
    "        property2 = cells[2].text.strip()\n",
    "        # assign property1 and property2 to variables if not in list of Strings\n",
    "        strings_to_avoid = ['Light', 'Bold', 'Dry', 'Sweet', 'Soft', \"Acidic\"]\n",
    "        if property1 not in strings_to_avoid and property2 not in strings_to_avoid:\n",
    "            specialCategory1 = property1\n",
    "            specialCategory2 = property2\n",
    "        \n",
    "        # Print the properties and the percentage\n",
    "        #print((int(percentage)+7.5)*0.01)\n",
    "        #print(property1, property2)\n",
    "        #append to percentages\n",
    "        percentages.append((int(percentage)+7.5)*0.01)\n",
    "\n",
    "    # Find all span tags with the class 'tasteNote__flavorGroup--1Uaen'\n",
    "    flavor_group_spans = soup.find_all('span', class_='tasteNote__flavorGroup--1Uaen')\n",
    "\n",
    "    # Extract the text from each span tag\n",
    "    flavor_groups = [span.text.strip().capitalize() for span in flavor_group_spans]\n",
    "\n",
    "    # Find all div tags with the class 'tasteNote__popularKeywords--1gIa2'\n",
    "    popular_keywords_divs = soup.find_all('div', class_='tasteNote__popularKeywords--1gIa2')\n",
    "\n",
    "    # Extract the text from each div tag, remove words that contain \"...\"\n",
    "    popular_keywords = [' '.join(word.capitalize() for word in div.text.split() if \"...\" not in word) for div in popular_keywords_divs]\n",
    "\n",
    "    popular_keywords = [keyword[:-1] if keyword.endswith(',') else keyword for keyword in popular_keywords]\n",
    "\n",
    "    # Pair each flavor group with its corresponding popular keywords\n",
    "    groupings = dict(zip(flavor_groups, popular_keywords))\n",
    "\n",
    "    # Get only the first three groupings\n",
    "    first_three_groupings = {k: groupings[k] for k in list(groupings)[:3]}\n",
    "\n",
    "    # Format each key-value pair into a string and add it to the list\n",
    "    main_impressions = [f\"{k} ({v})\" for k, v in first_three_groupings.items()]\n",
    "\n",
    "\n",
    "    # Find all div tags with the class 'foodPairing__foodImage--2OYHg'\n",
    "    food_divs = soup.find_all('div', class_='foodPairing__foodImage--2OYHg')\n",
    "\n",
    "    # Extract the aria-label attribute from each div tag\n",
    "    foods = [div.get('aria-label') for div in food_divs]\n",
    "    foods = [re.sub(r'\\(.*?\\)', '', food) for food in foods]\n",
    "\n",
    "    # Use join to convert the list to a string\n",
    "    food_pairing = ', '.join(foods)\n",
    "    # replace \" , \" with \", \"\n",
    "    food_pairing = food_pairing.replace(\" , \", \", \")\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    # Find the a tag\n",
    "    tag = soup.find('a', {'class': 'anchor_anchor__m8Qi- wineTasteStyle-desktop__readMore--7NbVI anchor_vivinoLink__q1fW2'})\n",
    "\n",
    "    # Get the href attribute of the tag\n",
    "    href = tag.get('href')\n",
    "\n",
    "    url = \"https://www.vivino.com/\"+href  # Outputs: /wine-styles/bordeaux-left-bank-pauillac\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(1) # gives an implicit wait for 20 seconds\n",
    "\n",
    "    sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #save soup as html file\n",
    "    #with open('sub_vivino.html', 'w') as file:\n",
    "    #    file.write(str(sub_soup))\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    # Find the div tag with class=\"wine-style-page__header__description__content\"\n",
    "    tag = sub_soup.find('div', {'class': 'wine-style-page__header__description__content'})\n",
    "\n",
    "    # Get the text of the tag\n",
    "    content = tag.text\n",
    "\n",
    "\n",
    "    # Create a dictionary with the scraped data\n",
    "    scraped_data = {\n",
    "        'Name': [name], \n",
    "        'Picture ID': [name+\" \"+year], \n",
    "        'Year': [int(year)], \n",
    "        'Rating': [\"\"],\n",
    "        'Price Range': [\"\"],\n",
    "        'Winery': [winery],\n",
    "        'Winery Description': [\"\"],\n",
    "        'Country': [country],\n",
    "        'Region': [region],\n",
    "        'Category': [category],\n",
    "        'Light-to-Bold': [percentages[0]],\n",
    "        'Cat1-to-Cat2': [percentages[1]],\n",
    "        'Dry-to-Sweet': [percentages[2]],\n",
    "        'Soft-to-Acidic': [percentages[3]],\n",
    "        'SpecialCat1': [specialCategory1],\n",
    "        'SpecialCat12': [specialCategory2],\n",
    "        'Grapes': [grape_type],\n",
    "        'Wine Style': [wine_style],\n",
    "        'Wine Style Description': [content],\n",
    "        'Alcohol': [\"\"],\n",
    "        'Main Impressions A': [main_impressions[0]],\n",
    "        'Main Impressions B': [main_impressions[1]],\n",
    "        'Main Impressions C': [main_impressions[2]],\n",
    "        'Food Pairing': [food_pairing],\n",
    "        'Notes': [\"\"],\n",
    "        'Color': [\"\"],\n",
    "        'New Line': [\"\"]\n",
    "    }\n",
    "    return scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = \"Latour\"\n",
    "vintage = \"2017\"\n",
    "\n",
    "scraped_data = scrape_vivino(search, vintage)\n",
    "\n",
    "# Read the existing Excel file into a DataFrame\n",
    "df = pd.read_excel('../Factsheet Automation/Wineportfolio Database.xlsx')\n",
    "\n",
    "# Create a new DataFrame from the scraped data\n",
    "new_data = pd.DataFrame(scraped_data)\n",
    "\n",
    "# Concatenate the new data to the DataFrame\n",
    "df = pd.concat([df, new_data], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame back to the Excel file\n",
    "df.to_excel('test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new instance of the Firefox driver\n",
    "# driver = webdriver.Firefox()\n",
    "\n",
    "# # Find the a tag\n",
    "# tag = soup.find('a', {'class': 'winery'})\n",
    "\n",
    "# # Get the href attribute of the tag\n",
    "# href = tag.get('href')\n",
    "\n",
    "# url = \"https://www.vivino.com/\"+href  # Outputs: /wine-styles/bordeaux-left-bank-pauillac\n",
    "# driver.get(url)\n",
    "# driver.implicitly_wait(1) # gives an implicit wait for 20 seconds\n",
    "\n",
    "# sub_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# #save soup as html file\n",
    "# with open('sub_vivino.html', 'w') as file:\n",
    "#     file.write(str(sub_soup))\n",
    "# # Close the driver\n",
    "# driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
